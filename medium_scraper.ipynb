{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce16e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b14129c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_url_builder(tag):\n",
    "    #builds the base url\n",
    "    url = \"https://medium.com/tag/\" + tag +\"/archive/\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4008d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_date(year, month, day):\n",
    "    #checks if start date is valid and converts to start time object\n",
    "    try:\n",
    "        start_date = datetime(year, month, day)\n",
    "    except:\n",
    "        raise Exception(\"Start date is in the wrong format or is invalid.\")\n",
    "    return start_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3032b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_date(year, month, day):\n",
    "    #checks if end date is valid and converts to date time object\n",
    "    try:\n",
    "        end_date = datetime(year, month, day)\n",
    "    except:\n",
    "        raise Exception(\"End date is in the wrong format or is invalid.\")\n",
    "    return end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8306396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_chrome():\n",
    "    #to open a chrome driver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.implicitly_wait(30)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce24865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_masher(base_url, year, month, day):\n",
    "    #makes new url with the given date\n",
    "    month = \"0\" + month\n",
    "    if len(day) == 1:\n",
    "        day = \"0\" + day\n",
    "    url = base_url + year + \"/\" + month + \"/\" + day\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65f298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_post_cards(soup):\n",
    "    #pulls each card from the feed.Each card contains author name, title, claps, published date,etc\n",
    "    cards = soup.find_all(\"div\", class_=\"streamItem streamItem--postPreview js-streamItem\")\n",
    "    return cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cfca4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_from_cards(cards):\n",
    "    #gets title of article from cards\n",
    "    def title_cleaner(title):\n",
    "        #REMOVE MEDIUMS ENCODING SYMBOLS AND EMOJIS FROM TITLES\n",
    "        title = title.replace(\"\\xa0\",\" \")\n",
    "        title = title.replace(\"\\u200a\",\"\")\n",
    "        title = title.replace(\"\\ufe0f\",\"\")\n",
    "        title = re.sub(r'[^\\x00-\\x7F]+','', title)\n",
    "        return title\n",
    "\n",
    "    titles=[]\n",
    "    for card in cards:\n",
    "        #search for title in 3 different classes\n",
    "        variant1 = card.find(\"h3\", class_=\"graf graf--h3 graf-after--figure graf--title\")\n",
    "        variant2 = card.find(\"h3\", class_=\"graf graf--h3 graf-after--figure graf--trailing graf--title\")\n",
    "        variant3 = card.find(\"h4\", class_=\"graf graf--h4 graf--leading\")\n",
    "        variant4 = card.find(\"h3\", class_=\"graf graf--h3 graf--leading graf--title\")\n",
    "        variant5 = card.find(\"p\", class_=\"graf graf--p graf--leading\")\n",
    "        variant6 = card.find(\"h3\", class_=\"graf graf--h3 graf--startsWithDoubleQuote graf--leading graf--title\")\n",
    "        variant7= card.find(\"h3\", class_=\"graf graf--h3 graf--startsWithDoubleQuote graf-after--figure graf--trailing graf--title\")\n",
    "        \n",
    "        variants = [variant1, variant2, variant3, variant4, variant5, variant6, variant7]\n",
    "        saved = False\n",
    "        #save the first title entry from the above variants\n",
    "        for variant in variants:\n",
    "            if ((variant is not None) and (not saved)):\n",
    "                title = variant.text\n",
    "                title = title_cleaner(title)\n",
    "                titles.append(title)\n",
    "                saved = True\n",
    "        if not saved:\n",
    "            titles.append(\"NaN\")\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d5ed483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_and_pubs_from_cards(cards):\n",
    "    # gets author and publication details from each card\n",
    "    authors = []\n",
    "    pubs = []\n",
    "    for card in cards:\n",
    "        # get the author and publication\n",
    "        author = card.find(\"a\", class_=\"ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken\")\n",
    "        pub = card.find(\"a\", class_=\"ds-link ds-link--styleSubtle link--darken link--accent u-accentColor--textNormal\")\n",
    "        if author is not None:\n",
    "            text = author.text\n",
    "            text = re.sub('\\s+[^A-Za-z]', '', text)\n",
    "            text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
    "            authors.append(text)\n",
    "        else:\n",
    "            authors.append(\"NaN\")\n",
    "        if pub is not None:\n",
    "            text2 = pub.text\n",
    "            text2 = re.sub('\\s+[^A-Za-z]', '', text2)\n",
    "            text2 = re.sub(r'[^\\x00-\\x7F]+',' ', text2)\n",
    "            pubs.append(text2)\n",
    "        else:\n",
    "            pubs.append(\"NaN\")\n",
    "    return authors, pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065638b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates_and_tags(tag, year,month,day,cards):\n",
    "    #gets date and tags of the cards\n",
    "    Year=[]\n",
    "    Month=[]\n",
    "    Day = []\n",
    "    tags=[]\n",
    "    for card in cards:\n",
    "        tags.append(tag)\n",
    "        Year.append(year)\n",
    "        Month.append(month)\n",
    "        Day.append(day)\n",
    "    return Year, Month, Day, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447aedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readTime_from_cards(cards):\n",
    "    #gets the reading time of each article card\n",
    "    readingTimes=[]\n",
    "    for card in cards:\n",
    "        time = card.find(\"span\", class_=\"readingTime\")\n",
    "        if time is not None:\n",
    "            time = time['title']\n",
    "            time = time.replace(\" min read\", \"\")\n",
    "            readingTimes.append(time)\n",
    "        else:\n",
    "            readingTimes.append(\"0\")\n",
    "    return readingTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a19cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_applause_from_cards(cards):\n",
    "    #gets claps of the cards\n",
    "    applause=[]\n",
    "    for card in cards:\n",
    "        claps=card.find(\"button\", class_=\"button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents\")\n",
    "        if claps is not None:\n",
    "            applause.append(claps.text)\n",
    "        else:\n",
    "            applause.append(\"0\")\n",
    "    return applause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04fcd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_from_cards(cards):\n",
    "    #gets article url from cards\n",
    "    urls = []\n",
    "    for card in cards:\n",
    "        url = card.find(\"a\", class_=\"\")\n",
    "        if url is not None:\n",
    "            urls.append(url['href'])\n",
    "        else:\n",
    "            raise Exception(\"couldnt find a url\")\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdcf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_urls_from_cards(cards):\n",
    "    #gets author url from cards\n",
    "    auth_urls = []\n",
    "    for card in cards:\n",
    "        url = card.find(\"a\", class_=\"ds-link ds-link--styleSubtle link link--darken link--accent u-accentColor--textNormal u-accentColor--textDarken\")\n",
    "        if url is not None:\n",
    "            auth_urls.append(url['href'])\n",
    "        else:\n",
    "            auth_urls.append(\"NaN\")\n",
    "    return auth_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c002ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tag(tag, yearstart, monthstart, yearstop, monthstop):\n",
    "    #Function to scrap details from the url based on tag and date\n",
    "    \n",
    "    path = os.getcwd()\n",
    "    path = path + \"/TAG_SCRAPES/medium_\"+tag+\".csv\"\n",
    "    \n",
    "    #opening the file path\n",
    "    try:\n",
    "        file = open(path, \"w\")\n",
    "        file.close()\n",
    "    except:\n",
    "        raise Exception(\"Could not open file.\")\n",
    "\n",
    "    #check if start date, end date is valid\n",
    "    current_date = get_start_date(int(yearstart), int(monthstart), 1)\n",
    "    end_date = get_start_date(int(yearstop), int(monthstop), 1)\n",
    "    if current_date > end_date:\n",
    "        raise Exception(\"End date exceeds start date.\")\n",
    "    else:\n",
    "        None\n",
    "        \n",
    "    #buld the base url\n",
    "    base_url = base_url_builder(tag)\n",
    "    #opening the chrome driver\n",
    "    chrome_driver = open_chrome()\n",
    "\n",
    "    firstPage=True\n",
    "    counter=0\n",
    "\n",
    "    #START ITERATION OVER DATES\n",
    "    while(current_date <= end_date):\n",
    "        #bulid url from the current date\n",
    "        url = url_masher(base_url,\n",
    "                        str(current_date.year),\n",
    "                        str(current_date.month),\n",
    "                        str(current_date.day))\n",
    "\n",
    "        #parse web responses using chrome driver and  beautiful soup\n",
    "        response = chrome_driver.get(url)\n",
    "        soup = BeautifulSoup(chrome_driver.page_source, features='lxml')\n",
    "\n",
    "        #find all story cards with article and author details\n",
    "        cards = find_post_cards(soup)\n",
    "\n",
    "        #scrape title, author, pulblication ,date, reading time ,claps,article url and author url from cards\n",
    "        titles = get_titles_from_cards(cards)\n",
    "        authors, pubs = get_auth_and_pubs_from_cards(cards)\n",
    "        year, month, day, tags = get_dates_and_tags(tag,\n",
    "                                        current_date.year,\n",
    "                                        current_date.month,\n",
    "                                        current_date.day,\n",
    "                                        cards)\n",
    "        readingTimes = get_readTime_from_cards(cards)\n",
    "        applause = get_applause_from_cards(cards)\n",
    "        urls = get_urls_from_cards(cards)\n",
    "        auth_urls = get_auth_urls_from_cards(cards)\n",
    "\n",
    "        #store data in a dictonary\n",
    "        dict = {\"Title\":titles,\"Author\":authors, \"Publication\":pubs, \"Year\":year, \"Month\":month, \"Day\":day, \"Tag\":tags, \"Reading_Time\":readingTimes, \"Claps\":applause, \"url\":urls, \"Author_url\":auth_urls}\n",
    "\n",
    "        #check if all the dictionary values are of same length\n",
    "        vals = list(dict.values())\n",
    "        for col in vals:\n",
    "            if len(col)==len(cards):\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(\"Data length does not match number of stories on page.\")\n",
    "\n",
    "        #store the dictonary items to a dataframe\n",
    "        df = pd.DataFrame.from_dict(dict)\n",
    "\n",
    "        #append data from dataframe to a csv file\n",
    "        if firstPage:\n",
    "            with open(path, 'a') as f:\n",
    "                df.to_csv(f, mode=\"a\", header=True, index = False)\n",
    "            firstPage=False\n",
    "        else:\n",
    "            with open(path, 'a') as f:\n",
    "                df.to_csv(f, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        #adda a date to the current date for next url call\n",
    "        current_date = current_date + timedelta(days=1)\n",
    "\n",
    "        #prints the number of cards/artilce details saved to csv\n",
    "        counter = counter + len(cards)\n",
    "        print(counter, \"    \",current_date)\n",
    "        time.sleep(2)\n",
    "    chrome_driver.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b4a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags to scrape\n",
    "tags = [\"data-science\"]\n",
    "\n",
    "#specify the dates to be scraped\n",
    "yearstart=2021\n",
    "monthstart=1\n",
    "yearstop=2021\n",
    "monthstop=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d290bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113      2021-01-02 00:00:00\n",
      "228      2021-01-03 00:00:00\n",
      "346      2021-01-04 00:00:00\n",
      "514      2021-01-05 00:00:00\n",
      "648      2021-01-06 00:00:00\n",
      "806      2021-01-07 00:00:00\n",
      "930      2021-01-08 00:00:00\n",
      "1070      2021-01-09 00:00:00\n",
      "1180      2021-01-10 00:00:00\n",
      "1320      2021-01-11 00:00:00\n",
      "1495      2021-01-12 00:00:00\n",
      "1658      2021-01-13 00:00:00\n",
      "1814      2021-01-14 00:00:00\n",
      "1944      2021-01-15 00:00:00\n",
      "2084      2021-01-16 00:00:00\n",
      "2176      2021-01-17 00:00:00\n",
      "2293      2021-01-18 00:00:00\n",
      "2457      2021-01-19 00:00:00\n",
      "2620      2021-01-20 00:00:00\n",
      "2801      2021-01-21 00:00:00\n",
      "2931      2021-01-22 00:00:00\n",
      "3044      2021-01-23 00:00:00\n",
      "3133      2021-01-24 00:00:00\n",
      "3246      2021-01-25 00:00:00\n",
      "3382      2021-01-26 00:00:00\n",
      "3560      2021-01-27 00:00:00\n",
      "3714      2021-01-28 00:00:00\n",
      "3846      2021-01-29 00:00:00\n",
      "3976      2021-01-30 00:00:00\n",
      "4072      2021-01-31 00:00:00\n",
      "4186      2021-02-01 00:00:00\n",
      "4338      2021-02-02 00:00:00\n",
      "4480      2021-02-03 00:00:00\n",
      "4589      2021-02-04 00:00:00\n",
      "4727      2021-02-05 00:00:00\n",
      "4870      2021-02-06 00:00:00\n",
      "4990      2021-02-07 00:00:00\n",
      "5097      2021-02-08 00:00:00\n",
      "5279      2021-02-09 00:00:00\n",
      "5427      2021-02-10 00:00:00\n",
      "5562      2021-02-11 00:00:00\n",
      "5708      2021-02-12 00:00:00\n",
      "5825      2021-02-13 00:00:00\n",
      "5900      2021-02-14 00:00:00\n",
      "5988      2021-02-15 00:00:00\n",
      "6136      2021-02-16 00:00:00\n",
      "6288      2021-02-17 00:00:00\n",
      "6429      2021-02-18 00:00:00\n",
      "6562      2021-02-19 00:00:00\n",
      "6705      2021-02-20 00:00:00\n",
      "6795      2021-02-21 00:00:00\n",
      "6898      2021-02-22 00:00:00\n",
      "7064      2021-02-23 00:00:00\n",
      "7195      2021-02-24 00:00:00\n",
      "7326      2021-02-25 00:00:00\n",
      "7461      2021-02-26 00:00:00\n",
      "7558      2021-02-27 00:00:00\n",
      "7628      2021-02-28 00:00:00\n",
      "7728      2021-03-01 00:00:00\n",
      "7875      2021-03-02 00:00:00\n",
      "8014      2021-03-03 00:00:00\n",
      "8128      2021-03-04 00:00:00\n",
      "8261      2021-03-05 00:00:00\n",
      "8384      2021-03-06 00:00:00\n",
      "8464      2021-03-07 00:00:00\n",
      "8589      2021-03-08 00:00:00\n",
      "8724      2021-03-09 00:00:00\n",
      "8855      2021-03-10 00:00:00\n",
      "8970      2021-03-11 00:00:00\n",
      "9076      2021-03-12 00:00:00\n",
      "9213      2021-03-13 00:00:00\n",
      "9296      2021-03-14 00:00:00\n",
      "9394      2021-03-15 00:00:00\n",
      "9526      2021-03-16 00:00:00\n",
      "9667      2021-03-17 00:00:00\n",
      "9784      2021-03-18 00:00:00\n",
      "9920      2021-03-19 00:00:00\n",
      "10026      2021-03-20 00:00:00\n",
      "10119      2021-03-21 00:00:00\n",
      "10213      2021-03-22 00:00:00\n",
      "10357      2021-03-23 00:00:00\n",
      "10486      2021-03-24 00:00:00\n",
      "10589      2021-03-25 00:00:00\n",
      "10710      2021-03-26 00:00:00\n",
      "10843      2021-03-27 00:00:00\n",
      "10927      2021-03-28 00:00:00\n",
      "11008      2021-03-29 00:00:00\n",
      "11132      2021-03-30 00:00:00\n",
      "11242      2021-03-31 00:00:00\n",
      "11365      2021-04-01 00:00:00\n",
      "11500      2021-04-02 00:00:00\n",
      "11608      2021-04-03 00:00:00\n",
      "11702      2021-04-04 00:00:00\n",
      "11792      2021-04-05 00:00:00\n",
      "11917      2021-04-06 00:00:00\n",
      "12048      2021-04-07 00:00:00\n",
      "12186      2021-04-08 00:00:00\n",
      "12305      2021-04-09 00:00:00\n",
      "12408      2021-04-10 00:00:00\n",
      "12482      2021-04-11 00:00:00\n",
      "12560      2021-04-12 00:00:00\n",
      "12715      2021-04-13 00:00:00\n",
      "12841      2021-04-14 00:00:00\n",
      "12984      2021-04-15 00:00:00\n",
      "13092      2021-04-16 00:00:00\n",
      "13192      2021-04-17 00:00:00\n",
      "13285      2021-04-18 00:00:00\n",
      "13367      2021-04-19 00:00:00\n",
      "13515      2021-04-20 00:00:00\n",
      "13667      2021-04-21 00:00:00\n",
      "13789      2021-04-22 00:00:00\n",
      "13922      2021-04-23 00:00:00\n",
      "14027      2021-04-24 00:00:00\n",
      "14107      2021-04-25 00:00:00\n",
      "14233      2021-04-26 00:00:00\n",
      "14380      2021-04-27 00:00:00\n",
      "14506      2021-04-28 00:00:00\n",
      "14621      2021-04-29 00:00:00\n",
      "14732      2021-04-30 00:00:00\n",
      "14832      2021-05-01 00:00:00\n",
      "14919      2021-05-02 00:00:00\n",
      "15015      2021-05-03 00:00:00\n",
      "15146      2021-05-04 00:00:00\n",
      "15284      2021-05-05 00:00:00\n",
      "15410      2021-05-06 00:00:00\n",
      "15549      2021-05-07 00:00:00\n",
      "15677      2021-05-08 00:00:00\n",
      "15768      2021-05-09 00:00:00\n",
      "15849      2021-05-10 00:00:00\n",
      "15971      2021-05-11 00:00:00\n",
      "16083      2021-05-12 00:00:00\n",
      "16204      2021-05-13 00:00:00\n",
      "16327      2021-05-14 00:00:00\n",
      "16448      2021-05-15 00:00:00\n",
      "16515      2021-05-16 00:00:00\n",
      "16598      2021-05-17 00:00:00\n",
      "16737      2021-05-18 00:00:00\n",
      "16877      2021-05-19 00:00:00\n",
      "17021      2021-05-20 00:00:00\n",
      "17130      2021-05-21 00:00:00\n",
      "17244      2021-05-22 00:00:00\n",
      "17336      2021-05-23 00:00:00\n",
      "17439      2021-05-24 00:00:00\n",
      "17597      2021-05-25 00:00:00\n",
      "17762      2021-05-26 00:00:00\n",
      "17872      2021-05-27 00:00:00\n",
      "17999      2021-05-28 00:00:00\n",
      "18133      2021-05-29 00:00:00\n",
      "18226      2021-05-30 00:00:00\n",
      "18332      2021-05-31 00:00:00\n",
      "18469      2021-06-01 00:00:00\n",
      "18624      2021-06-02 00:00:00\n",
      "18737      2021-06-03 00:00:00\n",
      "18843      2021-06-04 00:00:00\n",
      "18970      2021-06-05 00:00:00\n",
      "19072      2021-06-06 00:00:00\n",
      "19195      2021-06-07 00:00:00\n",
      "19333      2021-06-08 00:00:00\n",
      "19485      2021-06-09 00:00:00\n",
      "19634      2021-06-10 00:00:00\n",
      "19777      2021-06-11 00:00:00\n",
      "19881      2021-06-12 00:00:00\n",
      "19973      2021-06-13 00:00:00\n",
      "20066      2021-06-14 00:00:00\n",
      "20208      2021-06-15 00:00:00\n",
      "20341      2021-06-16 00:00:00\n",
      "20480      2021-06-17 00:00:00\n",
      "20617      2021-06-18 00:00:00\n",
      "20754      2021-06-19 00:00:00\n",
      "20854      2021-06-20 00:00:00\n",
      "20971      2021-06-21 00:00:00\n",
      "21104      2021-06-22 00:00:00\n",
      "21239      2021-06-23 00:00:00\n",
      "21368      2021-06-24 00:00:00\n",
      "21513      2021-06-25 00:00:00\n",
      "21642      2021-06-26 00:00:00\n",
      "21728      2021-06-27 00:00:00\n",
      "21846      2021-06-28 00:00:00\n",
      "21982      2021-06-29 00:00:00\n",
      "22122      2021-06-30 00:00:00\n",
      "22275      2021-07-01 00:00:00\n",
      "22419      2021-07-02 00:00:00\n",
      "22531      2021-07-03 00:00:00\n",
      "22621      2021-07-04 00:00:00\n",
      "22718      2021-07-05 00:00:00\n",
      "22857      2021-07-06 00:00:00\n",
      "23004      2021-07-07 00:00:00\n",
      "23153      2021-07-08 00:00:00\n",
      "23297      2021-07-09 00:00:00\n",
      "23404      2021-07-10 00:00:00\n",
      "23498      2021-07-11 00:00:00\n",
      "23591      2021-07-12 00:00:00\n",
      "23723      2021-07-13 00:00:00\n",
      "23855      2021-07-14 00:00:00\n",
      "23984      2021-07-15 00:00:00\n",
      "24104      2021-07-16 00:00:00\n",
      "24218      2021-07-17 00:00:00\n",
      "24298      2021-07-18 00:00:00\n",
      "24404      2021-07-19 00:00:00\n",
      "24548      2021-07-20 00:00:00\n",
      "24676      2021-07-21 00:00:00\n",
      "24817      2021-07-22 00:00:00\n",
      "24934      2021-07-23 00:00:00\n",
      "25046      2021-07-24 00:00:00\n",
      "25127      2021-07-25 00:00:00\n",
      "25211      2021-07-26 00:00:00\n",
      "25359      2021-07-27 00:00:00\n",
      "25494      2021-07-28 00:00:00\n",
      "25614      2021-07-29 00:00:00\n",
      "25763      2021-07-30 00:00:00\n",
      "25883      2021-07-31 00:00:00\n",
      "25962      2021-08-01 00:00:00\n",
      "26063      2021-08-02 00:00:00\n",
      "26180      2021-08-03 00:00:00\n",
      "26302      2021-08-04 00:00:00\n",
      "26429      2021-08-05 00:00:00\n",
      "26564      2021-08-06 00:00:00\n",
      "26657      2021-08-07 00:00:00\n",
      "26722      2021-08-08 00:00:00\n",
      "26802      2021-08-09 00:00:00\n",
      "26948      2021-08-10 00:00:00\n",
      "27059      2021-08-11 00:00:00\n",
      "27194      2021-08-12 00:00:00\n",
      "27321      2021-08-13 00:00:00\n",
      "27423      2021-08-14 00:00:00\n",
      "27504      2021-08-15 00:00:00\n",
      "27545      2021-08-16 00:00:00\n",
      "27555      2021-08-17 00:00:00\n",
      "27565      2021-08-18 00:00:00\n",
      "27575      2021-08-19 00:00:00\n",
      "27585      2021-08-20 00:00:00\n",
      "27595      2021-08-21 00:00:00\n",
      "27605      2021-08-22 00:00:00\n",
      "27615      2021-08-23 00:00:00\n",
      "27625      2021-08-24 00:00:00\n",
      "27635      2021-08-25 00:00:00\n",
      "27645      2021-08-26 00:00:00\n",
      "27655      2021-08-27 00:00:00\n",
      "27665      2021-08-28 00:00:00\n",
      "27675      2021-08-29 00:00:00\n",
      "27685      2021-08-30 00:00:00\n",
      "27695      2021-08-31 00:00:00\n",
      "27705      2021-09-01 00:00:00\n",
      "27715      2021-09-02 00:00:00\n",
      "Done with tag:  data-science\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#scrapes all the article detials of the tags based on the given date and saves the details to a csv\n",
    "for tag in tags:\n",
    "    scrape_tag(tag, yearstart, monthstart, yearstop, monthstop)\n",
    "    print(\"Done with tag: \", tag)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc83814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
